{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to 画像生成 AI tutorial ‼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**対象レベル**  \n",
    "このチュートリアルはPythonチュートリアルの [4. その他の制御フローツール](https://docs.python.org/ja/3/tutorial/controlflow.html)の関数定義までの知識があることを前提としています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このtutorialではGAN(敵対的生成ネットワーク)を用いた画像生成についてやっていきます。コードブロックを一つ一つ実行していくと画像を生成してくれるAIモデルが出来上がります。  \n",
    "ここに出てくるプログラムコードを自分の手で書き写して実行してみると良いと思います。 \n",
    "ベースとなっているより詳しいチュートリアルはこちらです。  \n",
    "日本語: [【PyTorchチュートリアル⑪】DCGAN Tutorial](https://qiita.com/sudominoru/items/02f4b6313585f14b210c)  \n",
    "英語:[DCGAN TUTORIAL](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)  \n",
    "それでは始めていきましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意事項\n",
    "このチュートリアルは演算負荷が高いためGPU環境が必要です。  \n",
    "Google Colab で実行している方は、ページ上部から**ランタイム** &rarr; **ランタイムのタイプを変更** をクリックし **ハードウェアアクセラレータ** を *None* から *GPU* に変更してください。  \n",
    "GPUが使用可能かどうかは次のコードブロックを実行することで分かります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"GPU:\",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ・下準備\n",
    "さて、AIを作るための下準備をしていきましょう。勝手に画像を生成するAIが作れたらうれしいのですが、残念ながらそう簡単にはいきません。  \n",
    "AIを作るための先人の知恵と努力の塊である「ライブラリ」を使いますし、学習するためには大きなデータセットが必要です。  \n",
    "それではサクッと下準備をしてしまいましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリ\n",
    "```import Namae```や```from Namae1 import Namae2```ですでにインストールされているライブラリを使います。これからもちょくちょく出てきます。  \n",
    "ちなみにPythonのライブラリの主なインストール方法は```pip install Namae```です。詳しくは[公式ドキュメント](https://docs.python.org/ja/3/installing/index.html)を参照ください。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # Deep Learningのためのライブラリです。\n",
    "import torchvision # 画像処理のためのライブラリです。\n",
    "import torchvision.transforms as transforms # 画像処理のライブラリから「変換」に特化したものを持ってきます\n",
    "import numpy as np # 行列計算のためのライブラリです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私がよく使っている```torchsummaryX```をインストールします。モデルのパラメータ数などを見ることができるため重宝しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchsummaryX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット\n",
    "画像を生成することにもデータセットが必要です。画像生成といってもまったく新しい画像を一から生成するわけではなく、**あくまでデータセットに似ている新しい画像**を生成します。データセットがバリエーション豊かで膨大であればそれだけたくさんの種類の画像を生成することができます。  \n",
    "今回は犬の猫の画像のデータセットを使っていきましょう。(https://www.kaggle.com/zippyz/cats-and-dogs-breeds-classification-oxford-dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットをダウンロードします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットを前処理します。  \n",
    "多くの場合、AIモデルの入力は決まった形のデータである必要があります。ただの画像データを```torch.Tensor```という型にしたり、今回の場合は64x64にリサイズしたりします。\n",
    "今回使うImageFolderクラスの仕様上、サブフォルダーから読み込むので画像があるフォルダの一つ上を指定します。  \n",
    "```\n",
    "dataroot = path/to/images\n",
    "path/to/images\n",
    "    -> dog_cat_images \n",
    "        -> cat.jpg\n",
    "        -> dog.jpg\n",
    "        ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder # 画像があるフォルダをデータセットとして読み込むために使います。\n",
    "\n",
    "dataroot = \"data/images\" # 仕様上、サブフォルダーから読み込むので画像があるフォルダの一つ上を指定します。\n",
    "image_size = 64 # すべての画像はResizeとCentorCropを使用してこのサイズに変更されます。\n",
    "data_trans = transforms.Compose([       # Composeは処理をまとめるという意味です。\n",
    "    transforms.Resize(image_size),      # Resizeするときの辺の長さです。\n",
    "    transforms.CenterCrop(image_size),  # 画像の縦横の長さが異なる場合は中央を切り取ります。\n",
    "    transforms.ToTensor(),              # 画像データをtorch.Tensor型にします。ついでに各ピクセルの値が\n",
    "                                        # 0~1に正規化されます。\n",
    "    transforms.Normalize(mean=0.5, std=0.5),    # 各ピクセルの値からmeanを引き、stdで割ることで\n",
    "                                                # -1~1の範囲に正規化します。\n",
    "])\n",
    "# datarootとdata_trans(前処理)をImageFolderに渡してデータセットは完成です。\n",
    "dataset = ImageFolder(root=dataroot,transform=data_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データローダーを定義し、どんなデータセットか見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # 可視化のためのグラフ描画ライブラリです。\n",
    "\n",
    "BATCH_SIZE = 128 # 一度に取り出すデータの個数。大きいほど学習が速く進むが、計算量やメモリ使用料が増える。\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader( # データの取り出し方を決めるものです。\n",
    "    dataset,batch_size=BATCH_SIZE,\n",
    "    shuffle=True # 全データをシャッフルしながら取り出します。（重複なし）\n",
    ")\n",
    "\n",
    "real_batch = next(iter(dataloader)) # 1バッチ分取り出して\n",
    "real_batch = real_batch[0] # (data, )というタプル構造になっているのでこの処理が入ります。\n",
    "images = torchvision.utils.make_grid(real_batch[:64],padding=True, normalize=True) # 64枚をひとまとめにした画像を作って\n",
    "images = np.transpose(images.numpy(),(1,2,0)) # 描画用のデータ形式にして\n",
    "plt.figure(figsize=(8,8)) # 8x8inchの空の図を作成し\n",
    "plt.axis(\"off\") # 軸の描画を切ります。\n",
    "plt.title(\"Training Images\") # タイトルをつけて\n",
    "plt.imshow(images) # 画像を埋め込み、\n",
    "plt.show() # 描画！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ・AIモデルの定義\n",
    "さあAIモデルを定義していきましょう。GANが発表された当時は非常にトリッキーで注目されました。  \n",
    "GANは敵対的生成ネットワークと訳されるように、Generator(生成器)とDiscriminator(判別器)が競い合うことによって学習します。DiscriminatorはGeneratorが生成した画像か本物の画像が分類できるように学習します。GeneratorはDiscriminatorを騙せる本物のような画像を生成するように学習します。 \n",
    "例えるなら、偽札を作る犯罪者と取り締まる警察でしょうか。このようなループを繰り返すことによってGeneratorが成長し、画像が生成されていくのです！  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator (生成器)\n",
    "まずはGeneratorを定義していきましょう。すこし理解するのが難しいかもしれませんが、Generatorの入力には標準分布に従うランダムノイズを投入します。ランダムなノイズから画像を生成すると考えればよいでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn # ある一つの機能を持った、「レイヤー」というものをひとまとめにしたものです。\n",
    "\n",
    "nc = 3 # トレーニング画像のチャネル数。カラー画像の場合は「3」 \n",
    "nz = 100 # Generatorに入力するランダムノイズのサイズです。\n",
    "ngf = 64 # num generator features の略で、モデルの大きさを設定するハイパーパラメータにします。\n",
    "\n",
    "class Generator(nn.Module): # nn.Moduleを継承して、\n",
    "    def __init__(self):     # コンストラクタを定義します。\n",
    "        super().__init__()  # 継承元のコンストラクタを呼び出します。\n",
    "\n",
    "        self.main = nn.Sequential( # この中にレイヤーを順々に定義していきます。定義した順にしたがってデータは通されます。\n",
    "            # 入力は BATCH_SIZE x nz x 1 x 1 のサイズのランダムノイズです。\n",
    "            nn.ConvTranspose2d( # 画像を拡大する畳み込み層です。 \n",
    "                in_channels=nz, out_channels=ngf*8,# 画像のカラーチャネルをnz -> nfg*8 にします。\n",
    "                kernel_size=(4,4), # 畳み込みレイヤーのフィルターサイズです。\n",
    "                stride=1,   # フィルターを横にスライドする時のステップするピクセル数です。出力される画像サイズは約stride倍されます。\n",
    "                padding=0,  # 画像の縁を何ピクセル増やすかを指定します。出力されるデータの形に影響します。\n",
    "                bias=False  # バイアスという加算のみをするパラメータをつけるか否かです。 \n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features=ngf * 8), # データの各チャネルをバッチ事に平均0、分散１に正規化します。\n",
    "            nn.ReLU(inplace=True), # Rectified Linear Unit という関数に通します。\n",
    "            # サイズ (ngf*8) x 4 x 4 （この時点で）\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False), # 先ほどの畳み込み層の定義と同様です。\n",
    "            nn.BatchNorm2d(ngf * 4), # 先ほどの正規化する層と同様です。\n",
    "            nn.ReLU(True),\n",
    "            # サイズ  (ngf*4) x 8 x 8（この時点で）\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2), \n",
    "            nn.ReLU(True),\n",
    "            # サイズ (ngf*2) x 16 x 16（この時点で）\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # サイズ (ngf) x 32 x 32（この時点で）\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh() # 出力するデータの値域を -1 ~ 1 にするために使います。\n",
    "            # サイズ (nc) x 64 x 64（この時点で）\n",
    "        )\n",
    "\n",
    "    def forward(self, input): # forwardメソッドを定義して、\n",
    "        return self.main(input) # 先ほど定義したSequentialにinputデータを通して、値を返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator (判別器)\n",
    "Generatorの定義が終わったので、今度は実際のデータかGeneratorが生成したデータかを見分ける Discriminatorを定義していきましょう。Discriminatorの入力は3x64x64の画像で、出力は真偽を表す 1つだけです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nc = 3 # ncは先ほど定義してあるためここでは定義しません。\n",
    "ndf = 64 # num discriminator features の略で、モデルの大きさを設定するハイパーパラメータにします。\n",
    "Leaky_slope = 0.2 # LeakyReLUの負の傾斜の値です。\n",
    "\n",
    "class Discriminator(nn.Module): # nn.Moduleを継承して、\n",
    "    def __init__(self):         # コンストラクタを定義します。\n",
    "        super().__init__()      # 継承元のコンストラクタを呼び出します。\n",
    "        \n",
    "        self.main = nn.Sequential( # Generatorの定義時と同様です。\n",
    "            # 入力は (nc) x 64 x 64\n",
    "            nn.Conv2d( # 畳み込みレイヤーです。\n",
    "                in_channels=nc, out_channels=ndf, # 画像のチャネルを nc -> ndfにします。\n",
    "                kernel_size=4,  # 先ほどと同様に畳み込みレイヤーのフィルターサイズです。\n",
    "                stride=2,       # 画像サイズはおおよそ 1/strideになります。\n",
    "                padding=1,      # 入力画像に上下左右に1ピクセル 0 を追加します。\n",
    "                bias=False      # バイアスという加算のみをするパラメータをつけるか否かです。  \n",
    "            ),\n",
    "            nn.LeakyReLU(negative_slope=Leaky_slope, inplace=True), # Leaky Rectified Linear Unitという関数に通します。\n",
    "            # サイズ (ndf) x 32 x 32 （この時点で）\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False), # 先ほどの畳み込み層の定義と同様です。\n",
    "            nn.BatchNorm2d(ndf * 2), # 先ほどと同じ正規化する層です。\n",
    "            nn.LeakyReLU(0.2, True), \n",
    "            # サイズ (ndf*2) x 16 x 16（この時点で）\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # サイズ (ndf*4) x 8 x 8（この時点で）\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # サイズ (ndf*8) x 4 x 4（この時点で）\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid() # データの値域を 0 ~ 1 にします。\n",
    "        )\n",
    "\n",
    "    def forward(self, input): # forwardメソッドを定義して\n",
    "        return self.main(input) # 先ほど定義したSequentialに入力データを通します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各レイヤーについて\n",
    "このチュートリアルでは各レイヤーの仕組みについては解説しませんので、気になる方は次のリンクを参照ください。  \n",
    "[Conv2d]()  \n",
    "[ConvTranspose2d]()  \n",
    "[BatchNorm2d]()  \n",
    "[ReLU]()  \n",
    "[LeakyReLU]()  \n",
    "[Tanh]()  \n",
    "[Sigmoid]()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重み初期化について"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G（生成器）とD（識別器）の重みの初期化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルのインスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummaryX import summary\n",
    "\n",
    "# 実行するデバイスを決定する\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device = torch.device(device)\n",
    "\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_g_input = torch.randn(1,nz,1,1, device=device)\n",
    "dummy_d_input = torch.randn(1,nc,image_size,image_size,device=device)\n",
    "\n",
    "print(\"Generator\")\n",
    "summary(netG,dummy_g_input)\n",
    "print(\"Discriminator\")\n",
    "summary(netD,dummy_d_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=\"runs/Generator\")\n",
    "writer.add_graph(netG,dummy_g_input)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=\"runs/Discriminator\")\n",
    "writer.add_graph(netD, dummy_d_input)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ・学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam \n",
    "\n",
    "# BCELoss関数を初期化します\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# ジェネレータの進行を視覚化するために使用する潜在ベクトルを作成します\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# トレーニング中に本物のラベルと偽のラベルのルールを設定します\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# G と D に Adam オプティマイザを設定する\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "optimizerD = Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "num_epochs = 5\n",
    "log_interval = 10\n",
    "\n",
    "def train():\n",
    "    print(\"Start Training roop...\")\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    writer = SummaryWriter(log_dir=\"runs/\"+now)\n",
    "    current_step = 0\n",
    "    img_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for i, data in enumerate(dataloader,0):\n",
    "            ### Discirminator の更新 #################\n",
    "            ## \n",
    "            netD.zero_grad()\n",
    "\n",
    "            real_img = data[0].to(device)\n",
    "            b_size = real_img.size(0)\n",
    "            label = torch.full((b_size, ),fill_value=real_label)\n",
    "            label = label.type_as(real_img)\n",
    "\n",
    "            output = netD(real_img)\n",
    "            output = output.view(-1)\n",
    "            errD_real = criterion(output, label)\n",
    "            # 逆伝播でDの勾配を計算します\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            ## 偽の画像でトレーニングします\n",
    "            # 潜在ベクトルのバッチを生成します\n",
    "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "            # Gで偽の画像を生成します\n",
    "            fake = netG(noise)\n",
    "            label.fill_(fake_label)\n",
    "            # 生成した偽画像をDで分類します\n",
    "            output = netD(fake.detach()).view(-1)\n",
    "            # Dの損失を計算します\n",
    "            errD_fake = criterion(output, label)\n",
    "            # 勾配を計算します\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "\n",
    "            # 実在の画像の勾配と偽画像の勾配を加算します\n",
    "            errD = errD_real + errD_fake\n",
    "\n",
    "            optimizerD.step()\n",
    "\n",
    "            ############################\n",
    "            # (2) Gネットワ​​ークの更新：log(D(G(z))) を最大化します\n",
    "            ###########################\n",
    "            netG.zero_grad()\n",
    "            label.fill_(real_label)  # 偽のラベルは生成器の損失にとって本物です\n",
    "            # パラメータ更新後のDを利用して、偽画像を順伝播させます\n",
    "            output = netD(fake).view(-1)\n",
    "            # この出力に基づいてGの損失を計算します\n",
    "            errG = criterion(output, label)\n",
    "            # Gの勾配を計算します\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            # Gを更新します\n",
    "            optimizerG.step()\n",
    "\n",
    "            if current_step % log_interval == 0:\n",
    "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                    % (epoch, num_epochs, i, len(dataloader),\n",
    "                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2)\n",
    "                )\n",
    "\n",
    "                writer.add_scalar(\"Loss_D\",errD.item(),current_step)\n",
    "                writer.add_scalar(\"Loss_G\",errG.item(),current_step)\n",
    "\n",
    "            current_step += 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake = netG(fixed_noise)\n",
    "            fake = fake.detach().cpu()\n",
    "        img = torchvision.utils.make_grid(fake, padding=2, normalize=True)\n",
    "        img_list.append(img)\n",
    "        writer.add_image(\"Generated Image\",img,current_step)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    return img_list        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### どうやって画像生成器を作るのか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 実は大変なGANの学習 -モード崩壊について-\n",
    "もしGeneratorの学習が変な方向に進んだ結果、とてつもなく高品質な画像1枚だけを生成するようになってしまったとしても、Generatorの学習目的としては成功したことになります。こういった生成データのバリエーションが極端に乏しく学習が進んでしまうことを**モード崩壊**といいます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 記録について"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"runs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ・実行してみよう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルを保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(netD.state_dict(),\"Discriminator.pth\")\n",
    "torch.save(netG.state_dict(),\"Generator.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルをロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#netD.load_state_dict(torch.load(\"Discriminator.pth\",map_location=device))\n",
    "#netG.load_state_dict(torch.load(\"Generator.pth\",map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ・結果を見てみよう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import matplotlib.animation as animation\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ランダムに生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    noise = torch.randn(1,nz, 1,1,device=device)\n",
    "    fake = netG(noise).cpu() * 0.5 + 0.5\n",
    "    fake = fake.squeeze(0).permute(1,2,0)\n",
    "plt.imshow(fake)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# 再現性のためにランダムシードを設定する\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint（1、10000）＃新しい結果が必要な場合に使用\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"data/images\"\n",
    "\n",
    "# データローダーのワーカー数\n",
    "workers = 0\n",
    "\n",
    "# トレーニングのバッチサイズ\n",
    "batch_size = 128\n",
    "\n",
    "# トレーニング画像の空間サイズ。\n",
    "# すべての画像はトランスフォーマーを使用してこのサイズに変更されます。\n",
    "image_size = 64\n",
    "\n",
    "# トレーニング画像のチャネル数。カラー画像の場合は「3」 \n",
    "nc = 3\n",
    "\n",
    "# 潜在ベクトル z のサイズ（つまり、ジェネレータ入力のサイズ）\n",
    "nz = 100\n",
    "\n",
    "# 生成器の feature map のサイズ\n",
    "ngf = 64\n",
    "\n",
    "# 識別器の feature map のサイズ\n",
    "ndf = 64\n",
    "\n",
    "# エポック数\n",
    "num_epochs = 50\n",
    "\n",
    "# 学習率\n",
    "lr = 0.0002\n",
    "\n",
    "# Adam オプティマイザのBeta1ハイパーパラメータ\n",
    "beta1 = 0.5\n",
    "\n",
    "# 使用可能なGPUの数。0の場合、CPUモードで実行されます\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像フォルダデータセットは、以下で設定した方法で使用できます。\n",
    "\n",
    "# データセットを作成する\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# データローダーを作成する\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "# 実行するデバイスを決定する\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# トレーニング画像をプロットする\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G（生成器）とD（識別器）の重みの初期化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # 入力は Z で、畳み込み層に渡されます\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # サイズ (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # サイズ  (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # サイズ (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # サイズ (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # サイズ (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ジェネレーターを作成します\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# 必要に応じてGPUを使用します\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# weights_init関数を適用して、すべての重みを平均「0」、標準偏差「0.02」でランダムに初期化します。\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# モデルを出力します\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # 入力は (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # サイズ (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # サイズ (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # サイズ (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # サイズ (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "# 識別器を作成します\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "# 必要に応じてGPUを使用します\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "# weights_init関数を適用して、すべての重みを平均「0」、標準偏差「0.02」でランダムに初期化します。\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "# モデルを出力します\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BCELoss関数を初期化します\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# ジェネレータの進行を視覚化するために使用する潜在ベクトルを作成します\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# トレーニング中に本物のラベルと偽のラベルのルールを設定します\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# G と D に Adam オプティマイザを設定する\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングループ\n",
    "\n",
    "# 進捗状況を追跡するためのリスト\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# エポックごとのループ\n",
    "for epoch in range(num_epochs):\n",
    "    # データローダーのバッチごとのループ\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Dネットワークの更新：log(D(x)) + log(1 - D(G(z))) を最大化します\n",
    "        ###########################\n",
    "        ## 実在の画像でトレーニングします\n",
    "        netD.zero_grad()\n",
    "        # バッチのフォーマット\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # 実在の写真で D の順伝播させます\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # 損失を計算します\n",
    "        errD_real = criterion(output, label)\n",
    "        # 逆伝播でDの勾配を計算します\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## 偽の画像でトレーニングします\n",
    "        # 潜在ベクトルのバッチを生成します\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Gで偽の画像を生成します\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # 生成した偽画像をDで分類します\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Dの損失を計算します\n",
    "        errD_fake = criterion(output, label)\n",
    "        # 勾配を計算します\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # 実在の画像の勾配と偽画像の勾配を加算します\n",
    "        errD = errD_real + errD_fake\n",
    "        # Dを更新します\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Gネットワ​​ークの更新：log(D(G(z))) を最大化します\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # 偽のラベルは生成器の損失にとって本物です\n",
    "        # パラメータ更新後のDを利用して、偽画像を順伝播させます\n",
    "        output = netD(fake).view(-1)\n",
    "        # この出力に基づいてGの損失を計算します\n",
    "        errG = criterion(output, label)\n",
    "        # Gの勾配を計算します\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Gを更新します\n",
    "        optimizerG.step()\n",
    "\n",
    "        # トレーニング統計を出力します\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # 後でプロットするために損失を保存します\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # fixed_noiseによる G の出力を保存し、生成器の精度を確認します\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(netD.state_dict(),\"Discriminator.pth\")\n",
    "torch.save(netG.state_dict(),\"Generator.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4467f1926f03d6fcd44316305074fb8c0b3cdc10977f45ea461091401ebc85a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('JARVIS': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
