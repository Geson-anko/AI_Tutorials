{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to 画像生成 AI tutorial ‼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**対象レベル**  \n",
    "このチュートリアルはPythonチュートリアルの [4. その他の制御フローツール](https://docs.python.org/ja/3/tutorial/controlflow.html)の関数定義までの知識があることを前提としています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このtutorialではGAN(敵対的生成ネットワーク)を用いた画像生成についてやっていきます。コードブロックを一つ一つ実行していくと画像を生成してくれるAIモデルが出来上がります。  \n",
    "ここに出てくるプログラムコードを自分の手で書き写して実行してみると良いと思います。 \n",
    "ベースとなっているより詳しいチュートリアルはこちらです。  \n",
    "日本語: [【PyTorchチュートリアル⑪】DCGAN Tutorial](https://qiita.com/sudominoru/items/02f4b6313585f14b210c)  \n",
    "英語:[DCGAN TUTORIAL](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)  \n",
    "それでは始めていきましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意事項\n",
    "このチュートリアルは演算負荷が高いためGPU環境が必要です。  \n",
    "Google Colab で実行している方は、ページ上部から**ランタイム** &rarr; **ランタイムのタイプを変更** をクリックし **ハードウェアアクセラレータ** を *None* から *GPU* に変更してください。  \n",
    "GPUが使用可能かどうかは次のコードブロックを実行することで分かります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"GPU:\",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ・下準備\n",
    "さて、AIを作るための下準備をしていきましょう。勝手に画像を生成するAIが作れたらうれしいのですが、残念ながらそう簡単にはいきません。  \n",
    "AIを作るための先人の知恵と努力の塊である「ライブラリ」を使いますし、学習するためには大きなデータセットが必要です。  \n",
    "それではサクッと下準備をしてしまいましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリ\n",
    "```import Namae```や```from Namae1 import Namae2```ですでにインストールされているライブラリを使います。これからもちょくちょく出てきます。  \n",
    "ちなみにPythonのライブラリの主なインストール方法は```pip install Namae```です。詳しくは[公式ドキュメント](https://docs.python.org/ja/3/installing/index.html)を参照ください。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # Deep Learningのためのライブラリです。\n",
    "import torchvision # 画像処理のためのライブラリです。\n",
    "import torchvision.transforms as transforms # 画像処理のライブラリから「変換」に特化したものを持ってきます\n",
    "import numpy as np # 行列計算のためのライブラリです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私がよく使っている```torchsummaryX```をインストールします。モデルのパラメータ数などを見ることができるため重宝しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchsummaryX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット\n",
    "画像を生成することにもデータセットが必要です。画像生成といってもまったく新しい画像を一から生成するわけではなく、**あくまでデータセットに似ている新しい画像**を生成します。データセットがバリエーション豊かで膨大であればそれだけたくさんの種類の画像を生成することができます。  \n",
    "今回は犬の猫の画像のデータセットを使っていきましょう。(https://www.kaggle.com/zippyz/cats-and-dogs-breeds-classification-oxford-dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットをダウンロードします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットを前処理します。  \n",
    "多くの場合、AIモデルの入力は決まった形のデータである必要があります。ただの画像データを```torch.Tensor```という型にしたり、今回の場合は64x64にリサイズしたりします。\n",
    "今回使うImageFolderクラスの仕様上、サブフォルダーから読み込むので画像があるフォルダの一つ上を指定します。  \n",
    "```\n",
    "dataroot = path/to/images\n",
    "path/to/images\n",
    "    -> dog_cat_images \n",
    "        -> cat.jpg\n",
    "        -> dog.jpg\n",
    "        ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder # 画像があるフォルダをデータセットとして読み込むために使います。\n",
    "\n",
    "dataroot = \"data/images\" # 仕様上、サブフォルダーから読み込むので画像があるフォルダの一つ上を指定します。\n",
    "image_size = 64 # すべての画像はResizeとCentorCropを使用してこのサイズに変更されます。\n",
    "data_trans = transforms.Compose([       # Composeは処理をまとめるという意味です。\n",
    "    transforms.Resize(image_size),      # Resizeするときの辺の長さです。\n",
    "    transforms.CenterCrop(image_size),  # 画像の縦横の長さが異なる場合は中央を切り取ります。\n",
    "    transforms.ToTensor(),              # 画像データをtorch.Tensor型にします。ついでに各ピクセルの値が\n",
    "                                        # 0~1に正規化されます。\n",
    "    transforms.Normalize(mean=0.5, std=0.5),    # 各ピクセルの値からmeanを引き、stdで割ることで\n",
    "                                                # -1~1の範囲に正規化します。\n",
    "])\n",
    "# datarootとdata_trans(前処理)をImageFolderに渡してデータセットは完成です。\n",
    "dataset = ImageFolder(root=dataroot,transform=data_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データローダーを定義し、どんなデータセットか見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # 可視化のためのグラフ描画ライブラリです。\n",
    "\n",
    "BATCH_SIZE = 128 # 一度に取り出すデータの個数。大きいほど学習が速く進むが、計算量やメモリ使用料が増える。\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader( # データの取り出し方を決めるものです。\n",
    "    dataset,batch_size=BATCH_SIZE,\n",
    "    shuffle=True # 全データをシャッフルしながら取り出します。（重複なし）\n",
    ")\n",
    "\n",
    "real_batch = next(iter(dataloader)) # 1バッチ分取り出して\n",
    "real_batch = real_batch[0] # (data, )というタプル構造になっているのでこの処理が入ります。\n",
    "images = torchvision.utils.make_grid(real_batch[:64],padding=True, normalize=True) # 64枚をひとまとめにした画像を作って\n",
    "images = np.transpose(images.numpy(),(1,2,0)) # 描画用のデータ形式にして\n",
    "plt.figure(figsize=(8,8)) # 8x8inchの空の図を作成し\n",
    "plt.axis(\"off\") # 軸の描画を切ります。\n",
    "plt.title(\"Training Images\") # タイトルをつけて\n",
    "plt.imshow(images) # 画像を埋め込み、\n",
    "plt.show() # 描画！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ・AIモデルの定義\n",
    "さあAIモデルを定義していきましょう。GANが発表された当時は非常にトリッキーで注目されました。  \n",
    "GANは敵対的生成ネットワークと訳されるように、Generator(生成器)とDiscriminator(判別器)が競い合うことによって学習します。DiscriminatorはGeneratorが生成した画像か本物の画像が分類できるように学習します。GeneratorはDiscriminatorを騙せる本物のような画像を生成するように学習します。 \n",
    "例えるなら、偽札を作る犯罪者と取り締まる警察でしょうか。このようなループを繰り返すことによってGeneratorが成長し、画像が生成されていくのです！  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator (生成器)\n",
    "まずはGeneratorを定義していきましょう。すこし理解するのが難しいかもしれませんが、Generatorの入力には標準分布に従うランダムノイズを投入します。ランダムなノイズから画像を生成すると考えればよいでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn # ある一つの機能を持った、「レイヤー」というものをひとまとめにしたものです。\n",
    "\n",
    "nc = 3 # トレーニング画像のチャネル数。カラー画像の場合は「3」 \n",
    "nz = 100 # Generatorに入力するランダムノイズのサイズです。\n",
    "ngf = 64 # num generator features の略で、モデルの大きさを設定するハイパーパラメータにします。\n",
    "\n",
    "class Generator(nn.Module): # nn.Moduleを継承して、\n",
    "    def __init__(self):     # コンストラクタを定義します。\n",
    "        super().__init__()  # 継承元のコンストラクタを呼び出します。\n",
    "\n",
    "        self.main = nn.Sequential( # この中にレイヤーを順々に定義していきます。定義した順にしたがってデータは通されます。\n",
    "            # 入力は BATCH_SIZE x nz x 1 x 1 のサイズのランダムノイズです。\n",
    "            nn.ConvTranspose2d( # 画像を拡大する畳み込み層です。 \n",
    "                in_channels=nz, out_channels=ngf*8,# 画像のカラーチャネルをnz -> nfg*8 にします。\n",
    "                kernel_size=(4,4), # 畳み込みレイヤーのフィルターサイズです。\n",
    "                stride=1,   # フィルターを横にスライドする時のステップするピクセル数です。出力される画像サイズは約stride倍されます。\n",
    "                padding=0,  # 画像の縁を何ピクセル増やすかを指定します。出力されるデータの形に影響します。\n",
    "                bias=False  # バイアスという加算のみをするパラメータをつけるか否かです。 \n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features=ngf * 8), # データの各チャネルをバッチ事に平均0、分散１に正規化します。\n",
    "            nn.ReLU(inplace=True), # Rectified Linear Unit という関数に通します。\n",
    "            # サイズ (ngf*8) x 4 x 4 （この時点で）\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False), # 先ほどの畳み込み層の定義と同様です。\n",
    "            nn.BatchNorm2d(ngf * 4), # 先ほどの正規化する層と同様です。\n",
    "            nn.ReLU(True),\n",
    "            # サイズ  (ngf*4) x 8 x 8（この時点で）\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2), \n",
    "            nn.ReLU(True),\n",
    "            # サイズ (ngf*2) x 16 x 16（この時点で）\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # サイズ (ngf) x 32 x 32（この時点で）\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh() # 出力するデータの値域を -1 ~ 1 にするために使います。\n",
    "            # サイズ (nc) x 64 x 64（この時点で）\n",
    "        )\n",
    "\n",
    "    def forward(self, input): # forwardメソッドを定義して、\n",
    "        return self.main(input) # 先ほど定義したSequentialにinputデータを通して、値を返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator (判別器)\n",
    "Generatorの定義が終わったので、今度は実際のデータかGeneratorが生成したデータかを見分ける Discriminatorを定義していきましょう。Discriminatorの入力は3x64x64の画像で、出力は真偽を表す 1つだけです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nc = 3 # ncは先ほど定義してあるためここでは定義しません。\n",
    "ndf = 64 # num discriminator features の略で、モデルの大きさを設定するハイパーパラメータにします。\n",
    "Leaky_slope = 0.2 # LeakyReLUの負の傾斜の値です。\n",
    "\n",
    "class Discriminator(nn.Module): # nn.Moduleを継承して、\n",
    "    def __init__(self):         # コンストラクタを定義します。\n",
    "        super().__init__()      # 継承元のコンストラクタを呼び出します。\n",
    "        \n",
    "        self.main = nn.Sequential( # Generatorの定義時と同様です。\n",
    "            # 入力は (nc) x 64 x 64\n",
    "            nn.Conv2d( # 畳み込みレイヤーです。\n",
    "                in_channels=nc, out_channels=ndf, # 画像のチャネルを nc -> ndfにします。\n",
    "                kernel_size=4,  # 先ほどと同様に畳み込みレイヤーのフィルターサイズです。\n",
    "                stride=2,       # 画像サイズはおおよそ 1/strideになります。\n",
    "                padding=1,      # 入力画像に上下左右に1ピクセル 0 を追加します。\n",
    "                bias=False      # バイアスという加算のみをするパラメータをつけるか否かです。  \n",
    "            ),\n",
    "            nn.LeakyReLU(negative_slope=Leaky_slope, inplace=True), # Leaky Rectified Linear Unitという関数に通します。\n",
    "            # サイズ (ndf) x 32 x 32 （この時点で）\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False), # 先ほどの畳み込み層の定義と同様です。\n",
    "            nn.BatchNorm2d(ndf * 2), # 先ほどと同じ正規化する層です。\n",
    "            nn.LeakyReLU(0.2, True), \n",
    "            # サイズ (ndf*2) x 16 x 16（この時点で）\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # サイズ (ndf*4) x 8 x 8（この時点で）\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # サイズ (ndf*8) x 4 x 4（この時点で）\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid() # データの値域を 0 ~ 1 にします。\n",
    "        )\n",
    "\n",
    "    def forward(self, input): # forwardメソッドを定義して\n",
    "        return self.main(input) # 先ほど定義したSequentialに入力データを通します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各レイヤーについて\n",
    "このチュートリアルでは各レイヤーの仕組みについては解説しませんので、気になる方は次のリンクを参照ください。  \n",
    "[Conv2d]()  \n",
    "[ConvTranspose2d]()  \n",
    "[BatchNorm2d]()  \n",
    "[ReLU]()  \n",
    "[LeakyReLU]()  \n",
    "[Tanh]()  \n",
    "[Sigmoid]()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重み初期化について\n",
    "DCGANの重みの値はすべて平均0.0, 標準偏差 0.02に従ったガウス分布によって初期化されます。（論文中で詳しくその理由は明かされませんでした）現在はもっと良い重み初期化の手法が確立されていると思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G（生成器）とD（識別器）の重みの初期化\n",
    "def weights_init(m): # `m`odule（レイヤー）を受け取って\n",
    "    classname = m.__class__.__name__    # 名前の中に\n",
    "    if classname.find('Conv') != -1:    # `Conv`が含まれていれば\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02) # 平均0.0, 標準偏差0.02の標準(normal)分布で初期化\n",
    "    elif classname.find('BatchNorm') != -1: # `BatchNorm`が含まれていれば\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02) # 平均1.0, 標準偏差0.02で初期化します。\n",
    "                                                  # BatchNormのパラメータは少々特殊で、乗数γとして扱われるので平均1.0になります。\n",
    "        nn.init.constant_(m.bias.data, 0)   # 加算のみが行われるバイアス項の初期値は0です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルのインスタンス化 (コンストラクト)\n",
    "さて、先ほどまでで定義したモデルをインスタンス化します（設計図から実際のものを作るようなものです。）  \n",
    "Pytorchで作ったAIモデルはデータを通すまで実はモデルの形（計算グラフ）が構築されません。ですのでダミーデータを作成してモデル通し、実際のデータの流れや計算量を可視化します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter # `tensorboard`というグラフィカルな可視化ツールに記録するためのものです。\n",
    "from torchsummaryX import summary # 計算量や学習可能パラメータの数等を見るためのツールです。\n",
    "\n",
    "# 実行するデバイスを決定する\n",
    "if torch.cuda.is_available(): # GPU (cuda) が使えるのなら\n",
    "    device = \"cuda:0\" # deviceに\"cuda:0\" を代入\n",
    "else:                 # 使えなければ\n",
    "    device = \"cpu\"    # CPU を使う\n",
    "\n",
    "device = torch.device(device) # torch.deviceクラスに変換します。この行がなくても動きます。\n",
    "\n",
    "netG = Generator().to(device) # Generatorを構築し、演算デバイスへ送ります。\n",
    "netD = Discriminator().to(device) # Discriminatorを構築し、演算デバイスへ送ります。\n",
    "\n",
    "netG.apply(weights_init) # 重み初期化を適用します。内部でレイヤーが一つ一つ\n",
    "netD.apply(weights_init) # weight_init(m)に通されていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの可視化\n",
    "ダミーデータを使ってモデルを可視化します。Tensorboard記録されたモデルの形（計算グラフ）を見るための方法は後述の **記録について** で説明しますのでそのまま実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_g_input = torch.randn(1,nz,1,1, device=device) # 1 x 100 x 1 x 1 のダミーデータを用意して\n",
    "dummy_d_input = torch.randn(1,nc,image_size,image_size,device=device) # 1 x 3 x 64 x 64 のダミーデータを用意して\n",
    "\n",
    "print(\"Generator\")          # Generatorの計算量やパラメータ数を出します。\n",
    "summary(netG,dummy_g_input) # 勝手に内部でGeneratorにダミーデータを通してくれます。\n",
    "print(\"Discriminator\")      # Discriminatorも同様に\n",
    "summary(netD,dummy_d_input) # します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=\"runs/Generator\") # Generator用のログを作ります。\n",
    "writer.add_graph(netG,dummy_g_input) # 勝手に内部でGeneratorにダミーデータを通してくれます。\n",
    "writer.close()  # ちゃんと閉じて二回連続で書き込まれないようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=\"runs/Discriminator\") # 先ほどと同様にDiscriminator用のログディレクトリを作って\n",
    "writer.add_graph(netD, dummy_d_input) # 通して\n",
    "writer.close() # 閉めます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ・学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さあモデルの定義も可視化も終わったことですし、ついに学習の流れを決めてきます。 GANはGeneratorとDiscriminatorを交互に学習するため少し手順が複雑です。さらに、GeneratorとDiscriminatorを競わせるため、`誤差` の取り方がそれぞれ異なります。  \n",
    "そもそも、深層学習のモデルは、出力と答えの **損失（誤差）** を最小化しようと学習（重みパラメータの更新）が行われます。\n",
    "今回使う `BCELoss` (Binary Cross Entropy Loss) は、出力を1か0のどちらか一方に集中させたいときに使います。正解ラベルを$y \\ | \\ 0 \\ or \\ 1$, 出力を$x \\ | [0,1]$ (0から1の範囲)とすると次のように損失（誤差）は定義されます。\n",
    "$$ -(y ⋅log \\ x +(1−y)⋅log(1−x))$$\n",
    "対数$-log \\ x$は、$x$ が1の時が最小になり、$-log(1-x)$ はxが0のときに最小になります。  \n",
    "つまり、正解ラベル$y$が 1 のときは上の式は$-log \\ x $ となり$x$は1になるように学習されますし、  \n",
    "正解ラベル$y$が 0 のときは上の式は $-log(1-x)$ となり$x$は 0 になるように学習されます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam # 重みの更新手法はAdamを採用します。\n",
    "\n",
    "# BCELoss関数を初期化します\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# ジェネレータの進行を視覚化するために使用する潜在ベクトルを作成します\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# トレーニング中に本物のラベルと偽のラベルのルールを設定します\n",
    "real_label = 1. # True\n",
    "fake_label = 0. # False\n",
    "\n",
    "# G と D に Adam オプティマイザを設定する\n",
    "lr = 0.0002 # 大きいほど1ステップでモデルの重みが大きく更新されます。論文中では 0.001が大きすぎてこの値だと安定したそうです。\n",
    "beta1 = 0.5 # 普段は0.9くらいなのですが、学習が不安定になるようなのでこの値となります。\n",
    "optimizerD = Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999)) # Discriminatorを更新するoptimizerを用意します。\n",
    "optimizerG = Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999)) # パラメータと学習率の設定は必須ですが、betasはデフォルト値を使うことも多いです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして実際の学習フローでは、最初にDiscriminatorを更新し、次にGeneratorを更新するという流れを繰り返していきます。  \n",
    "Discriminatorは実際のデータに対しては 1 を出力するように学習し、Generatorのフェイク画像に対しては 0 を出力するように学習します。  \n",
    "Generatorは画像を生成し、それをDiscriminatorに通した結果が 1 になるように学習されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime # 日付を取得するためのライブラリです。\n",
    "num_epochs = 5 # 全データを使って重みを更新する回数です。世代数と呼ばれたりもします。\n",
    "log_interval = 10 # 記録するときのインターバルステップ数です。\n",
    "\n",
    "def train(): # 学習関数を定義して、\n",
    "    print(\"Start Training roop...\") # 見えるようにプリント\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") # 日付を取ってきて文字列にして、\n",
    "    writer = SummaryWriter(log_dir=\"runs/\"+now) # 記録writerを初期化します。\n",
    "    current_step = 0 # 現在のステップ数\n",
    "    img_list = []   # 1 epoch ごとにGeneratorの生成した画像をここに入れます。あとで見るために。\n",
    "\n",
    "    for epoch in range(num_epochs): # 世代数のループを定義して、\n",
    "        \n",
    "        for i, data in enumerate(dataloader): # BATCHとなるdataとそのインデックス i をまわして、 \n",
    "            ### Discirminator の更新 #################\n",
    "            ## 真の画像でトレーニングします。\n",
    "            netD.zero_grad() # 重み更新のための勾配を0で初期化します。\n",
    "\n",
    "            real_img = data[0].to(device) # データを演算デバイスに送って、\n",
    "            b_size = real_img.size(0)   # batch_sizeを取得して、（最後のバッチはバッチサイズに満たないこともあるので）\n",
    "            label = torch.full((b_size, ),fill_value=real_label) # 1 で埋めたサイズ b_size のテンソルを作り、\n",
    "            label = label.type_as(real_img) # real_imgと同じデバイス、数値型にします。\n",
    "\n",
    "            output = netD(real_img) # Discriminatorに現実の画像を通して、\n",
    "            output = output.view(-1) # 形が(b_size x 1)なので (b_size )にして\n",
    "            errD_real = criterion(output, label) # 誤差を計算します。\n",
    "            # 逆伝播でDの勾配を計算します\n",
    "            errD_real.backward() # 誤差から勾配を計算します。\n",
    "            D_x = output.mean().item() # Discriminatorの現実の画像に対する平均判定率を出します。\n",
    "\n",
    "            ## 偽の画像でトレーニングします\n",
    "            noise = torch.randn(b_size, nz, 1, 1, device=device) # 潜在ベクトルのバッチを生成します\n",
    "            # Gで偽の画像を生成します\n",
    "            fake = netG(noise) # Generatorに通して、\n",
    "            label.fill_(fake_label) # ラベルを0で埋めなおして\n",
    "            # 生成した偽画像をDで分類します\n",
    "            output = netD(fake.detach()).view(-1)\n",
    "            # Dの損失を計算します\n",
    "            errD_fake = criterion(output, label)\n",
    "            # 勾配を計算します\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "\n",
    "            # 実在の画像の勾配と偽画像の勾配（損失）を加算します\n",
    "            errD = errD_real + errD_fake\n",
    "\n",
    "            optimizerD.step() # Discriminatorの重みを更新します。\n",
    "\n",
    "            ### Generator の更新 #################\n",
    "\n",
    "            netG.zero_grad() # 重み更新のための勾配を0で初期化します。\n",
    "            label.fill_(real_label)  # 偽のラベルは生成器の損失にとって本物です\n",
    "            # パラメータ更新後のDを利用して、偽画像を通します\n",
    "            output = netD(fake).view(-1)\n",
    "            # この出力に基づいてGの損失を計算します\n",
    "            errG = criterion(output, label)\n",
    "            # Gの勾配を計算します\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "\n",
    "            optimizerG.step() # Generatorの重みを更新します。\n",
    "\n",
    "            if current_step % log_interval == 0: # 現在のステップ数がlog_intervalの倍数の時、\n",
    "                # 結果を出力します。\n",
    "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                    % (epoch, num_epochs, i, len(dataloader),\n",
    "                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2)\n",
    "                )\n",
    "\n",
    "                # tensorboardにそれぞれLoss D, Loss G を記録します\n",
    "                writer.add_scalar(\"Loss_D\",errD.item(),current_step)\n",
    "                writer.add_scalar(\"Loss_G\",errG.item(),current_step)\n",
    "\n",
    "            current_step += 1 # 次のステップへ\n",
    "        \n",
    "        # 1 エポックが終了したら、\n",
    "        with torch.no_grad(): # 重み更新のための勾配計算を無効化して、\n",
    "            fake = netG(fixed_noise) # Generatorに画像を生成させます。\n",
    "            fake = fake.detach().cpu() # 演算デバイスからcpu上に移動させて、\n",
    "        img = torchvision.utils.make_grid(fake, padding=2, normalize=True) # グリッド画像を作ります。\n",
    "        img_list.append(img) # img_listに追加して、\n",
    "        writer.add_image(\"Generated Image\",img,current_step) # Tensorboardにも書き込んで、\n",
    "\n",
    "        # 1 エポックの処理は終わりです。\n",
    "    \n",
    "    # 学習が完了したら、\n",
    "    writer.close() # 記録Writerを閉じて、\n",
    "\n",
    "    return img_list # 学習中に保存しておいた img_listを返して終わりです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 実は大変なGANの学習 -モード崩壊について-\n",
    "もしGeneratorの学習が変な方向に進んだ結果、とてつもなく高品質な画像1枚だけを生成するようになってしまったとしても、Generatorの学習目的としては成功したことになります。こういった生成データのバリエーションが極端に乏しく学習が進んでしまうことを**モード崩壊**といいます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 記録について\n",
    "損失や各エポックでの生成画像ははtensorboardに記録します。tensorboardを起動するためには、ターミナルからこのノートブックのフォルダ内で次のコマンドを実行してください。    \n",
    "```tensorboard --logdir=\"runs\"```\n",
    "Google Colabで実行している場合は次のコードブロックを実行してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"runs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ・実行してみよう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = train() # 学習を走らせます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルを保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(netD.state_dict(),\"Discriminator.pth\") # このノートブックと同じフォルダに\n",
    "torch.save(netG.state_dict(),\"Generator.pth\")     # ファイルができているはずです。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデルをロードする\n",
    "学習済みのパラメータは次のコードブロックのコメントアウトを外し、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#netD.load_state_dict(torch.load(\"Discriminator.pth\",map_location=device))\n",
    "#netG.load_state_dict(torch.load(\"Generator.pth\",map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ・結果を見てみよう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import matplotlib.animation as animation\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ランダムに生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    noise = torch.randn(1,nz, 1,1,device=device)\n",
    "    fake = netG(noise).cpu() * 0.5 + 0.5\n",
    "    fake = fake.squeeze(0).permute(1,2,0)\n",
    "plt.imshow(fake)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# 再現性のためにランダムシードを設定する\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint（1、10000）＃新しい結果が必要な場合に使用\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"data/images\"\n",
    "\n",
    "# データローダーのワーカー数\n",
    "workers = 0\n",
    "\n",
    "# トレーニングのバッチサイズ\n",
    "batch_size = 128\n",
    "\n",
    "# トレーニング画像の空間サイズ。\n",
    "# すべての画像はトランスフォーマーを使用してこのサイズに変更されます。\n",
    "image_size = 64\n",
    "\n",
    "# トレーニング画像のチャネル数。カラー画像の場合は「3」 \n",
    "nc = 3\n",
    "\n",
    "# 潜在ベクトル z のサイズ（つまり、ジェネレータ入力のサイズ）\n",
    "nz = 100\n",
    "\n",
    "# 生成器の feature map のサイズ\n",
    "ngf = 64\n",
    "\n",
    "# 識別器の feature map のサイズ\n",
    "ndf = 64\n",
    "\n",
    "# エポック数\n",
    "num_epochs = 50\n",
    "\n",
    "# 学習率\n",
    "lr = 0.0002\n",
    "\n",
    "# Adam オプティマイザのBeta1ハイパーパラメータ\n",
    "beta1 = 0.5\n",
    "\n",
    "# 使用可能なGPUの数。0の場合、CPUモードで実行されます\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像フォルダデータセットは、以下で設定した方法で使用できます。\n",
    "\n",
    "# データセットを作成する\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# データローダーを作成する\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "# 実行するデバイスを決定する\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# トレーニング画像をプロットする\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G（生成器）とD（識別器）の重みの初期化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # 入力は Z で、畳み込み層に渡されます\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # サイズ (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # サイズ  (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # サイズ (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # サイズ (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # サイズ (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ジェネレーターを作成します\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# 必要に応じてGPUを使用します\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# weights_init関数を適用して、すべての重みを平均「0」、標準偏差「0.02」でランダムに初期化します。\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# モデルを出力します\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # 入力は (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # サイズ (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # サイズ (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # サイズ (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # サイズ (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "# 識別器を作成します\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "# 必要に応じてGPUを使用します\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "# weights_init関数を適用して、すべての重みを平均「0」、標準偏差「0.02」でランダムに初期化します。\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "# モデルを出力します\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BCELoss関数を初期化します\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# ジェネレータの進行を視覚化するために使用する潜在ベクトルを作成します\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# トレーニング中に本物のラベルと偽のラベルのルールを設定します\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# G と D に Adam オプティマイザを設定する\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングループ\n",
    "\n",
    "# 進捗状況を追跡するためのリスト\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# エポックごとのループ\n",
    "for epoch in range(num_epochs):\n",
    "    # データローダーのバッチごとのループ\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Dネットワークの更新：log(D(x)) + log(1 - D(G(z))) を最大化します\n",
    "        ###########################\n",
    "        ## 実在の画像でトレーニングします\n",
    "        netD.zero_grad()\n",
    "        # バッチのフォーマット\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # 実在の写真で D の順伝播させます\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # 損失を計算します\n",
    "        errD_real = criterion(output, label)\n",
    "        # 逆伝播でDの勾配を計算します\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## 偽の画像でトレーニングします\n",
    "        # 潜在ベクトルのバッチを生成します\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Gで偽の画像を生成します\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # 生成した偽画像をDで分類します\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Dの損失を計算します\n",
    "        errD_fake = criterion(output, label)\n",
    "        # 勾配を計算します\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # 実在の画像の勾配と偽画像の勾配を加算します\n",
    "        errD = errD_real + errD_fake\n",
    "        # Dを更新します\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Gネットワ​​ークの更新：log(D(G(z))) を最大化します\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # 偽のラベルは生成器の損失にとって本物です\n",
    "        # パラメータ更新後のDを利用して、偽画像を順伝播させます\n",
    "        output = netD(fake).view(-1)\n",
    "        # この出力に基づいてGの損失を計算します\n",
    "        errG = criterion(output, label)\n",
    "        # Gの勾配を計算します\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Gを更新します\n",
    "        optimizerG.step()\n",
    "\n",
    "        # トレーニング統計を出力します\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # 後でプロットするために損失を保存します\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # fixed_noiseによる G の出力を保存し、生成器の精度を確認します\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(netD.state_dict(),\"Discriminator.pth\")\n",
    "torch.save(netG.state_dict(),\"Generator.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4467f1926f03d6fcd44316305074fb8c0b3cdc10977f45ea461091401ebc85a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('JARVIS': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
